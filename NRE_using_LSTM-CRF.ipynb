{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j_VlxXyVwnoe"
   },
   "source": [
    "# Named Entity Recognition (NER) using Python and Keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EqifAu7vSkCE"
   },
   "source": [
    "## Part 2: Using CRF-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_jdz1Tn1dcVu"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "colab_type": "code",
    "id": "CPJSrU2Y0_r7",
    "outputId": "02f3eb1c-70ac-4eba-caf7-0ffe81d2c873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
      "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-c3_v22_b\n",
      "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-c3_v22_b\n",
      "Requirement already satisfied (use --upgrade to upgrade): keras-contrib==2.0.8 from git+https://www.github.com/keras-team/keras-contrib.git in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.4.3)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras->keras-contrib==2.0.8) (1.15.0)\n",
      "Building wheels for collected packages: keras-contrib\n",
      "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101066 sha256=0785fe6dba6a635a3ff7af5b5da81028cf2ff41b10877c19917af0fcca6d2219\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-tkabestx/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
      "Successfully built keras-contrib\n",
      "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (0.0.12)\n",
      "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras>=2.2.4->seqeval) (1.15.0)\n",
      "Collecting sklearn_crfsuite\n",
      "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n",
      "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
      "Collecting python-crfsuite>=0.8.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
      "\u001b[K     |████████████████████████████████| 747kB 5.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
      "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
      "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
    "!pip install seqeval\n",
    "!pip install sklearn_crfsuite\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import LSTM, Dense, TimeDistributed, Embedding, Bidirectional\n",
    "from keras.models import Model, Input\n",
    "from keras_contrib.layers import CRF\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "NTxyRKLGdrN-"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'https://raw.githubusercontent.com/RuchitaGarde/NLP_NER_using_Python_Keras_LSTM_CRF/master/ner_dataset.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "hXbkPtyOd00N",
    "outputId": "d7bec7a4-54ac-49de-bb0e-8b72e42e4b8b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS    Tag\n",
       "0  Sentence: 1      Thousands  NNS      O\n",
       "1          NaN             of   IN      O\n",
       "2          NaN  demonstrators  NNS      O\n",
       "3          NaN           have  VBP      O\n",
       "4          NaN        marched  VBN      O\n",
       "5          NaN        through   IN      O\n",
       "6          NaN         London  NNP  B-geo\n",
       "7          NaN             to   TO      O\n",
       "8          NaN        protest   VB      O\n",
       "9          NaN            the   DT      O"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "v3aBJl2JeI9e",
    "outputId": "d398fdba-43f6-4b14-8ff8-3d6654ca25bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim',\n",
       "       'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', 'B-nat', 'B-eve',\n",
       "       'I-eve', 'I-nat'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying the unique Tags\n",
    "df['Tag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "9leNtEVDfLm6",
    "outputId": "b017fb90-746d-4777-96ed-0552b7e1fff2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #    1000616\n",
       "Word                0\n",
       "POS                 0\n",
       "Tag                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking null values, if any.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "JCwTzOIRfTWZ"
   },
   "outputs": [],
   "source": [
    "# The huge number of missing values are due to 'Setence #'only being available for the first word of each sentence.\n",
    "df = df.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rotSGx4ifkUK"
   },
   "outputs": [],
   "source": [
    "# This is a class to get sentence. The each sentence will be list of tuples with its tag and pos.\n",
    "class sentence(object):\n",
    "    def __init__(self, df):\n",
    "        self.n_sent = 1\n",
    "        self.df = df\n",
    "        self.empty = False\n",
    "        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n",
    "                                                       s['POS'].values.tolist(),\n",
    "                                                       s['Tag'].values.tolist())]\n",
    "        self.grouped = self.df.groupby(\"Sentence #\").apply(agg)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_text(self):\n",
    "        try:\n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent +=1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "JBINgmOzfp_b",
    "outputId": "ad620094-234a-45a9-b5e4-104438763d3d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying one full sentence\n",
    "getter = sentence(df)\n",
    "sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "W-FF507EgYpA",
    "outputId": "ef974dda-1e1c-43d7-de75-35135eec66c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "#sentence with its pos and tag.\n",
    "sent = getter.get_text()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_8sSR_jDg4tC"
   },
   "source": [
    "Here word_to_index dictionary used to convert word into index value and tag_to_index is for the labels. So overall we represent each word as integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "DJBvIf2Og7JZ"
   },
   "outputs": [],
   "source": [
    "#Getting unique words and labels from data\n",
    "words = list(df['Word'].unique())\n",
    "tags = list(df['Tag'].unique())\n",
    "# Dictionary word:index pair\n",
    "# word is key and its value is corresponding index\n",
    "word_to_index = {w : i + 2 for i, w in enumerate(words)}\n",
    "word_to_index[\"UNK\"] = 1\n",
    "word_to_index[\"PAD\"] = 0\n",
    "\n",
    "# Dictionary lable:index pair\n",
    "# label is key and value is index.\n",
    "tag_to_index = {t : i + 1 for i, t in enumerate(tags)}\n",
    "tag_to_index[\"PAD\"] = 0\n",
    "\n",
    "idx2word = {i: w for w, i in word_to_index.items()}\n",
    "idx2tag = {i: w for w, i in tag_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XOMEnE98hahQ",
    "outputId": "6d654907-aeee-4117-e959-c4eab0f94170"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Thousands': 2,\n",
       " 'of': 3,\n",
       " 'demonstrators': 4,\n",
       " 'have': 5,\n",
       " 'marched': 6,\n",
       " 'through': 7,\n",
       " 'London': 8,\n",
       " 'to': 9,\n",
       " 'protest': 10,\n",
       " 'the': 11,\n",
       " 'war': 12,\n",
       " 'in': 13,\n",
       " 'Iraq': 14,\n",
       " 'and': 15,\n",
       " 'demand': 16,\n",
       " 'withdrawal': 17,\n",
       " 'British': 18,\n",
       " 'troops': 19,\n",
       " 'from': 20,\n",
       " 'that': 21,\n",
       " 'country': 22,\n",
       " '.': 23,\n",
       " 'Families': 24,\n",
       " 'soldiers': 25,\n",
       " 'killed': 26,\n",
       " 'conflict': 27,\n",
       " 'joined': 28,\n",
       " 'protesters': 29,\n",
       " 'who': 30,\n",
       " 'carried': 31,\n",
       " 'banners': 32,\n",
       " 'with': 33,\n",
       " 'such': 34,\n",
       " 'slogans': 35,\n",
       " 'as': 36,\n",
       " '\"': 37,\n",
       " 'Bush': 38,\n",
       " 'Number': 39,\n",
       " 'One': 40,\n",
       " 'Terrorist': 41,\n",
       " 'Stop': 42,\n",
       " 'Bombings': 43,\n",
       " 'They': 44,\n",
       " 'Houses': 45,\n",
       " 'Parliament': 46,\n",
       " 'a': 47,\n",
       " 'rally': 48,\n",
       " 'Hyde': 49,\n",
       " 'Park': 50,\n",
       " 'Police': 51,\n",
       " 'put': 52,\n",
       " 'number': 53,\n",
       " 'marchers': 54,\n",
       " 'at': 55,\n",
       " '10,000': 56,\n",
       " 'while': 57,\n",
       " 'organizers': 58,\n",
       " 'claimed': 59,\n",
       " 'it': 60,\n",
       " 'was': 61,\n",
       " '1,00,000': 62,\n",
       " 'The': 63,\n",
       " 'comes': 64,\n",
       " 'on': 65,\n",
       " 'eve': 66,\n",
       " 'annual': 67,\n",
       " 'conference': 68,\n",
       " 'Britain': 69,\n",
       " \"'s\": 70,\n",
       " 'ruling': 71,\n",
       " 'Labor': 72,\n",
       " 'Party': 73,\n",
       " 'southern': 74,\n",
       " 'English': 75,\n",
       " 'seaside': 76,\n",
       " 'resort': 77,\n",
       " 'Brighton': 78,\n",
       " 'party': 79,\n",
       " 'is': 80,\n",
       " 'divided': 81,\n",
       " 'over': 82,\n",
       " 'participation': 83,\n",
       " 'continued': 84,\n",
       " 'deployment': 85,\n",
       " '8,500': 86,\n",
       " 'march': 87,\n",
       " 'came': 88,\n",
       " 'ahead': 89,\n",
       " 'anti-war': 90,\n",
       " 'protests': 91,\n",
       " 'today': 92,\n",
       " 'other': 93,\n",
       " 'cities': 94,\n",
       " ',': 95,\n",
       " 'including': 96,\n",
       " 'Rome': 97,\n",
       " 'Paris': 98,\n",
       " 'Madrid': 99,\n",
       " 'International': 100,\n",
       " 'Atomic': 101,\n",
       " 'Energy': 102,\n",
       " 'Agency': 103,\n",
       " 'hold': 104,\n",
       " 'second': 105,\n",
       " 'day': 106,\n",
       " 'talks': 107,\n",
       " 'Vienna': 108,\n",
       " 'Wednesday': 109,\n",
       " 'how': 110,\n",
       " 'respond': 111,\n",
       " 'Iran': 112,\n",
       " 'resumption': 113,\n",
       " 'low-level': 114,\n",
       " 'uranium': 115,\n",
       " 'conversion': 116,\n",
       " 'this': 117,\n",
       " 'week': 118,\n",
       " 'restarted': 119,\n",
       " 'parts': 120,\n",
       " 'process': 121,\n",
       " 'its': 122,\n",
       " 'Isfahan': 123,\n",
       " 'nuclear': 124,\n",
       " 'plant': 125,\n",
       " 'Iranian': 126,\n",
       " 'officials': 127,\n",
       " 'say': 128,\n",
       " 'they': 129,\n",
       " 'expect': 130,\n",
       " 'get': 131,\n",
       " 'access': 132,\n",
       " 'sealed': 133,\n",
       " 'sensitive': 134,\n",
       " 'after': 135,\n",
       " 'an': 136,\n",
       " 'IAEA': 137,\n",
       " 'surveillance': 138,\n",
       " 'system': 139,\n",
       " 'begins': 140,\n",
       " 'functioning': 141,\n",
       " 'step': 142,\n",
       " 'will': 143,\n",
       " 'allow': 144,\n",
       " 'facility': 145,\n",
       " 'operate': 146,\n",
       " 'full': 147,\n",
       " 'capacity': 148,\n",
       " 'European': 149,\n",
       " 'Union': 150,\n",
       " 'U.S.': 151,\n",
       " 'backing': 152,\n",
       " 'has': 153,\n",
       " 'threatened': 154,\n",
       " 'refer': 155,\n",
       " 'U.N.': 156,\n",
       " 'Security': 157,\n",
       " 'Council': 158,\n",
       " 'which': 159,\n",
       " 'could': 160,\n",
       " 'impose': 161,\n",
       " 'sanctions': 162,\n",
       " 'if': 163,\n",
       " 'finds': 164,\n",
       " 'Tehran': 165,\n",
       " 'violated': 166,\n",
       " 'Nuclear': 167,\n",
       " 'Non-Proliferation': 168,\n",
       " 'treaty': 169,\n",
       " 'new': 170,\n",
       " 'President': 171,\n",
       " 'Mahmoud': 172,\n",
       " 'Ahmadinejad': 173,\n",
       " 'said': 174,\n",
       " 'Tuesday': 175,\n",
       " 'incentives': 176,\n",
       " 'aimed': 177,\n",
       " 'persuading': 178,\n",
       " 'end': 179,\n",
       " 'fuel': 180,\n",
       " 'program': 181,\n",
       " 'are': 182,\n",
       " 'insult': 183,\n",
       " 'nation': 184,\n",
       " 'Two': 185,\n",
       " 'Germans': 186,\n",
       " 'four': 187,\n",
       " 'Nigerian': 188,\n",
       " 'oil': 189,\n",
       " 'workers': 190,\n",
       " 'were': 191,\n",
       " 'kidnapped': 192,\n",
       " 'by': 193,\n",
       " 'armed': 194,\n",
       " 'militants': 195,\n",
       " 'during': 196,\n",
       " 'raid': 197,\n",
       " 'boat': 198,\n",
       " 'Nigeria': 199,\n",
       " 'oil-rich': 200,\n",
       " 'Delta': 201,\n",
       " 'region': 202,\n",
       " 'An': 203,\n",
       " 'official': 204,\n",
       " 'German': 205,\n",
       " 'firm': 206,\n",
       " 'Bilfinger': 207,\n",
       " 'Berger': 208,\n",
       " 'Thomas': 209,\n",
       " 'Horbach': 210,\n",
       " 'gunmen': 211,\n",
       " 'stopped': 212,\n",
       " 'supply': 213,\n",
       " 'sailed': 214,\n",
       " 'State': 215,\n",
       " 'Bayelsa': 216,\n",
       " 'inspect': 217,\n",
       " 'offshore': 218,\n",
       " 'field': 219,\n",
       " 'owned': 220,\n",
       " 'Royal-Dutch': 221,\n",
       " 'Shell': 222,\n",
       " 'works': 223,\n",
       " 'sub-contractor': 224,\n",
       " 'for': 225,\n",
       " 'Militant': 226,\n",
       " 'groups': 227,\n",
       " 'frequently': 228,\n",
       " 'attack': 229,\n",
       " 'operations': 230,\n",
       " 'Niger': 231,\n",
       " 'social': 232,\n",
       " 'services': 233,\n",
       " 'better': 234,\n",
       " 'job': 235,\n",
       " 'opportunities': 236,\n",
       " 'multinational': 237,\n",
       " 'companies': 238,\n",
       " 'Poor': 239,\n",
       " 'residents': 240,\n",
       " 'often': 241,\n",
       " 'complain': 242,\n",
       " 'been': 243,\n",
       " 'cheated': 244,\n",
       " 'out': 245,\n",
       " 'huge': 246,\n",
       " 'riches': 247,\n",
       " 'extracted': 248,\n",
       " 'their': 249,\n",
       " 'tribal': 250,\n",
       " 'lands': 251,\n",
       " '-': 252,\n",
       " 'where': 253,\n",
       " 'bulk': 254,\n",
       " '2.3': 255,\n",
       " 'million': 256,\n",
       " 'barrels': 257,\n",
       " 'petroleum': 258,\n",
       " 'pumped': 259,\n",
       " 'daily': 260,\n",
       " 'Suspected': 261,\n",
       " 'Islamist': 262,\n",
       " 'rebels': 263,\n",
       " 'fired': 264,\n",
       " 'mortar': 265,\n",
       " 'shells': 266,\n",
       " 'palace': 267,\n",
       " 'used': 268,\n",
       " 'Somalia': 269,\n",
       " 'interim': 270,\n",
       " 'Abdullahi': 271,\n",
       " 'Yusuf': 272,\n",
       " 'Ahmad': 273,\n",
       " 'It': 274,\n",
       " 'not': 275,\n",
       " 'immediately': 276,\n",
       " 'clear': 277,\n",
       " 'president': 278,\n",
       " 'Mogadishu': 279,\n",
       " 'when': 280,\n",
       " 'occurred': 281,\n",
       " 'or': 282,\n",
       " 'anyone': 283,\n",
       " 'hurt': 284,\n",
       " 'Local': 285,\n",
       " 'news': 286,\n",
       " 'reports': 287,\n",
       " 'least': 288,\n",
       " 'five': 289,\n",
       " 'hit': 290,\n",
       " 'compound': 291,\n",
       " 'mortars': 292,\n",
       " 'elsewhere': 293,\n",
       " 'attacks': 294,\n",
       " 'government': 295,\n",
       " 'go': 296,\n",
       " 'reconciliation': 297,\n",
       " 'more': 298,\n",
       " 'than': 299,\n",
       " '1,300': 300,\n",
       " 'Somali': 301,\n",
       " 'elders': 302,\n",
       " 'warlords': 303,\n",
       " 'politicians': 304,\n",
       " 'invited': 305,\n",
       " 'Iraqi': 306,\n",
       " 'military': 307,\n",
       " 'tanks': 308,\n",
       " 'arrived': 309,\n",
       " 'northern': 310,\n",
       " 'city': 311,\n",
       " 'Mosul': 312,\n",
       " 'offensive': 313,\n",
       " 'against': 314,\n",
       " 'al': 315,\n",
       " 'Qaida': 316,\n",
       " 'fighters': 317,\n",
       " 'Officials': 318,\n",
       " 'many': 319,\n",
       " 'Sunni': 320,\n",
       " 'Arab': 321,\n",
       " 'Kurdish': 322,\n",
       " 'bombings': 323,\n",
       " 'last': 324,\n",
       " '34': 325,\n",
       " 'people': 326,\n",
       " 'wounded': 327,\n",
       " '200': 328,\n",
       " 'commanders': 329,\n",
       " 'explained': 330,\n",
       " 'American': 331,\n",
       " 'forces': 332,\n",
       " 'participate': 333,\n",
       " 'fled': 334,\n",
       " 'successful': 335,\n",
       " 'campaigns': 336,\n",
       " 'them': 337,\n",
       " 'Anbar': 338,\n",
       " 'province': 339,\n",
       " 'Baghdad': 340,\n",
       " 'provinces': 341,\n",
       " 'largest': 342,\n",
       " 'north': 343,\n",
       " 'long': 344,\n",
       " 'stronghold': 345,\n",
       " 'militant': 346,\n",
       " 'In': 347,\n",
       " 'violence': 348,\n",
       " 'one': 349,\n",
       " 'soldier': 350,\n",
       " 'patrol': 351,\n",
       " 'Sunday': 352,\n",
       " 'Egyptian': 353,\n",
       " 'police': 354,\n",
       " 'arrested': 355,\n",
       " '16': 356,\n",
       " 'members': 357,\n",
       " 'opposition': 358,\n",
       " 'Muslim': 359,\n",
       " 'Brotherhood': 360,\n",
       " 'prepare': 361,\n",
       " 'parliamentary': 362,\n",
       " 'runoff': 363,\n",
       " 'elections': 364,\n",
       " 'Saturday': 365,\n",
       " 'arrests': 366,\n",
       " 'Friday': 367,\n",
       " 'Alexandria': 368,\n",
       " 'A': 369,\n",
       " 'spokesman': 370,\n",
       " 'attempt': 371,\n",
       " 'cut': 372,\n",
       " 'off': 373,\n",
       " 'supporters': 374,\n",
       " 'punishment': 375,\n",
       " 'winning': 376,\n",
       " 'seats': 377,\n",
       " 'earlier': 378,\n",
       " 'tripled': 379,\n",
       " 'strength': 380,\n",
       " 'parliament': 381,\n",
       " 'recent': 382,\n",
       " 'raising': 383,\n",
       " 'total': 384,\n",
       " '47': 385,\n",
       " 'voters': 386,\n",
       " 'cast': 387,\n",
       " 'ballots': 388,\n",
       " 'nine': 389,\n",
       " 'no': 390,\n",
       " 'candidate': 391,\n",
       " 'won': 392,\n",
       " 'majority': 393,\n",
       " 'previous': 394,\n",
       " 'round': 395,\n",
       " 'voting': 396,\n",
       " 'banned': 397,\n",
       " 'political': 398,\n",
       " 'but': 399,\n",
       " 'endorses': 400,\n",
       " 'so-called': 401,\n",
       " 'independent': 402,\n",
       " 'candidates': 403,\n",
       " 'whose': 404,\n",
       " 'allegiance': 405,\n",
       " 'known': 406,\n",
       " 'Hardline': 407,\n",
       " 'lawmakers': 408,\n",
       " 'Pakistan': 409,\n",
       " 'North': 410,\n",
       " 'West': 411,\n",
       " 'Frontier': 412,\n",
       " 'Province': 413,\n",
       " 'pushed': 414,\n",
       " 'law': 415,\n",
       " 'aims': 416,\n",
       " 'ensure': 417,\n",
       " 'Islamic': 418,\n",
       " 'correctness': 419,\n",
       " 'public': 420,\n",
       " 'places': 421,\n",
       " 'establishes': 422,\n",
       " 'morality': 423,\n",
       " 'enforce': 424,\n",
       " 'decent': 425,\n",
       " 'behavior': 426,\n",
       " 'six-party': 427,\n",
       " 'coalition': 428,\n",
       " 'religious': 429,\n",
       " 'based': 430,\n",
       " 'parties': 431,\n",
       " 'Mutahida': 432,\n",
       " 'Majlis-e-Amal': 433,\n",
       " 'dominates': 434,\n",
       " 'provincial': 435,\n",
       " 'assembly': 436,\n",
       " 'so': 437,\n",
       " 'bill': 438,\n",
       " 'easily': 439,\n",
       " 'passed': 440,\n",
       " 'Thursday': 441,\n",
       " 'vote': 442,\n",
       " '68-34': 443,\n",
       " 'governor': 444,\n",
       " 'must': 445,\n",
       " 'still': 446,\n",
       " 'sign': 447,\n",
       " 'before': 448,\n",
       " 'becomes': 449,\n",
       " 'seen': 450,\n",
       " 'only': 451,\n",
       " 'formality': 452,\n",
       " 'proposed': 453,\n",
       " 'calls': 454,\n",
       " 'setting': 455,\n",
       " 'up': 456,\n",
       " 'force': 457,\n",
       " 'make': 458,\n",
       " 'sure': 459,\n",
       " 'adhere': 460,\n",
       " 'values': 461,\n",
       " 'entertainment': 462,\n",
       " 'outlets': 463,\n",
       " 'close': 464,\n",
       " 'weekly': 465,\n",
       " 'prayers': 466,\n",
       " 'Violators': 467,\n",
       " 'be': 468,\n",
       " 'jailed': 469,\n",
       " 'six': 470,\n",
       " 'months': 471,\n",
       " 'denounced': 472,\n",
       " 'measure': 473,\n",
       " 'comparing': 474,\n",
       " 'draconian': 475,\n",
       " 'rule': 476,\n",
       " 'former': 477,\n",
       " 'Taleban': 478,\n",
       " 'neighboring': 479,\n",
       " 'Afghanistan': 480,\n",
       " 'man': 481,\n",
       " 'dressed': 482,\n",
       " 'suicide': 483,\n",
       " 'bomber': 484,\n",
       " 'demonstration': 485,\n",
       " 'publication': 486,\n",
       " 'cartoons': 487,\n",
       " 'depicting': 488,\n",
       " 'Islam': 489,\n",
       " 'Prophet': 490,\n",
       " 'Muhammad': 491,\n",
       " 'Bedfordshire': 492,\n",
       " 'Omar': 493,\n",
       " 'Khayam': 494,\n",
       " 'Bedford': 495,\n",
       " 'breaching': 496,\n",
       " 'conditions': 497,\n",
       " 'his': 498,\n",
       " 'parole': 499,\n",
       " 'Home': 500,\n",
       " 'Office': 501,\n",
       " 'sought': 502,\n",
       " 'investigation': 503,\n",
       " 'he': 504,\n",
       " 'photographed': 505,\n",
       " 'fatigues': 506,\n",
       " 'black': 507,\n",
       " 'cap': 508,\n",
       " 'bulky': 509,\n",
       " 'belt': 510,\n",
       " 'told': 511,\n",
       " 'Associated': 512,\n",
       " 'Press': 513,\n",
       " 'paroled': 514,\n",
       " 'offender': 515,\n",
       " 'gives': 516,\n",
       " 'cause': 517,\n",
       " 'concern': 518,\n",
       " 'can': 519,\n",
       " 'sent': 520,\n",
       " 'back': 521,\n",
       " 'prison': 522,\n",
       " 'AP': 523,\n",
       " 'also': 524,\n",
       " 'since': 525,\n",
       " 'year': 526,\n",
       " 'serving': 527,\n",
       " 'half': 528,\n",
       " 'six-year': 529,\n",
       " 'sentence': 530,\n",
       " 'drug': 531,\n",
       " 'dealing': 532,\n",
       " 'Pakistani': 533,\n",
       " 'unidentified': 534,\n",
       " 'three': 535,\n",
       " 'minister': 536,\n",
       " 'semi-autonomous': 537,\n",
       " 'bordering': 538,\n",
       " 'prominent': 539,\n",
       " 'leader': 540,\n",
       " 'Malik': 541,\n",
       " 'Faridullah': 542,\n",
       " 'Khan': 543,\n",
       " 'traveling': 544,\n",
       " 'South': 545,\n",
       " 'Waziristan': 546,\n",
       " 'vehicle': 547,\n",
       " 'ambushed': 548,\n",
       " 'Kani': 549,\n",
       " 'Wam': 550,\n",
       " 'area': 551,\n",
       " 'His': 552,\n",
       " 'driver': 553,\n",
       " 'elder': 554,\n",
       " 'No': 555,\n",
       " 'responsibility': 556,\n",
       " 'killings': 557,\n",
       " 'ambush': 558,\n",
       " 'commander': 559,\n",
       " 'army': 560,\n",
       " 'almost': 561,\n",
       " 'completely': 562,\n",
       " 'eliminated': 563,\n",
       " 'became': 564,\n",
       " 'refuge': 565,\n",
       " 'al-Qaida': 566,\n",
       " 'ousted': 567,\n",
       " '2001': 568,\n",
       " 'senior': 569,\n",
       " 'says': 570,\n",
       " 'wants': 571,\n",
       " 'what': 572,\n",
       " 'sordid': 573,\n",
       " 'chapter': 574,\n",
       " 'proliferation': 575,\n",
       " 'top': 576,\n",
       " 'scientists': 577,\n",
       " 'behind': 578,\n",
       " 'build': 579,\n",
       " 'civilian': 580,\n",
       " 'ties': 581,\n",
       " 'United': 582,\n",
       " 'States': 583,\n",
       " 'But': 584,\n",
       " 'ready': 585,\n",
       " 'scientist': 586,\n",
       " 'Abdul': 587,\n",
       " 'Qadeer': 588,\n",
       " 'available': 589,\n",
       " 'direct': 590,\n",
       " 'questioning': 591,\n",
       " 'sale': 592,\n",
       " 'secrets': 593,\n",
       " 'states': 594,\n",
       " 'Libya': 595,\n",
       " 'Korea': 596,\n",
       " 'He': 597,\n",
       " 'there': 598,\n",
       " 'reasons': 599,\n",
       " 'national': 600,\n",
       " 'sensitivities': 601,\n",
       " 'making': 602,\n",
       " 'him': 603,\n",
       " 'giving': 604,\n",
       " 'background': 605,\n",
       " 'briefing': 606,\n",
       " 'small': 607,\n",
       " 'group': 608,\n",
       " 'reporters': 609,\n",
       " 'Washington': 610,\n",
       " 'admitted': 611,\n",
       " '2004': 612,\n",
       " 'operated': 613,\n",
       " 'worldwide': 614,\n",
       " 'clandestine': 615,\n",
       " 'network': 616,\n",
       " 'sell': 617,\n",
       " 'technology': 618,\n",
       " 'market': 619,\n",
       " 'placed': 620,\n",
       " 'under': 621,\n",
       " 'house': 622,\n",
       " 'arrest': 623,\n",
       " 'Islamabad': 624,\n",
       " 'because': 625,\n",
       " 'considered': 626,\n",
       " 'father': 627,\n",
       " 'bomb': 628,\n",
       " 'Army': 629,\n",
       " 'renew': 630,\n",
       " 'controversial': 631,\n",
       " 'multi-billion': 632,\n",
       " 'dollar': 633,\n",
       " 'contract': 634,\n",
       " 'Halliburton': 635,\n",
       " 'company': 636,\n",
       " 'provide': 637,\n",
       " 'logistical': 638,\n",
       " 'support': 639,\n",
       " 'providing': 640,\n",
       " 'list': 641,\n",
       " 'meals': 642,\n",
       " 'communication': 643,\n",
       " 'several': 644,\n",
       " 'years': 645,\n",
       " 'Critics': 646,\n",
       " 'include': 647,\n",
       " 'auditors': 648,\n",
       " 'congressional': 649,\n",
       " 'Democrats': 650,\n",
       " 'produced': 651,\n",
       " 'some': 652,\n",
       " 'shoddy': 653,\n",
       " 'work': 654,\n",
       " 'charges': 655,\n",
       " 'too': 656,\n",
       " 'much': 657,\n",
       " 'money': 658,\n",
       " 'strongly': 659,\n",
       " 'denies': 660,\n",
       " 'allegations': 661,\n",
       " 'When': 662,\n",
       " 're-bidding': 663,\n",
       " 'chance': 664,\n",
       " 'compete': 665,\n",
       " 'portions': 666,\n",
       " 'Representatives': 667,\n",
       " 'Asia': 668,\n",
       " 'Pacific': 669,\n",
       " 'Economic': 670,\n",
       " 'Cooperation': 671,\n",
       " 'Business': 672,\n",
       " 'Advisory': 673,\n",
       " 'holding': 674,\n",
       " 'meetings': 675,\n",
       " 'finalize': 676,\n",
       " 'report': 677,\n",
       " 'APEC': 678,\n",
       " 'leaders': 679,\n",
       " 'summit': 680,\n",
       " 'September': 681,\n",
       " '8': 682,\n",
       " '9': 683,\n",
       " 'VOA': 684,\n",
       " 'Nancy-Amelia': 685,\n",
       " 'Collins': 686,\n",
       " 'Sydney': 687,\n",
       " 'security': 688,\n",
       " 'climate': 689,\n",
       " 'change': 690,\n",
       " 'World': 691,\n",
       " 'Trade': 692,\n",
       " 'Organization': 693,\n",
       " 'stalled': 694,\n",
       " 'negotiations': 695,\n",
       " 'investment': 696,\n",
       " 'all': 697,\n",
       " 'expected': 698,\n",
       " 'among': 699,\n",
       " 'major': 700,\n",
       " 'topics': 701,\n",
       " 'ABAC': 702,\n",
       " 'Tim': 703,\n",
       " 'Harcourt': 704,\n",
       " 'chief': 705,\n",
       " 'economist': 706,\n",
       " 'Australian': 707,\n",
       " 'Commission': 708,\n",
       " 'plays': 709,\n",
       " 'important': 710,\n",
       " 'role': 711,\n",
       " 'informing': 712,\n",
       " 'governments': 713,\n",
       " 'problems': 714,\n",
       " 'most': 715,\n",
       " 'thing': 716,\n",
       " 'business': 717,\n",
       " 'do': 718,\n",
       " 'tell': 719,\n",
       " 'logjams': 720,\n",
       " 'obstacles': 721,\n",
       " 'things': 722,\n",
       " 'improve': 723,\n",
       " 'I': 724,\n",
       " 'think': 725,\n",
       " 'actually': 726,\n",
       " 'played': 727,\n",
       " 'pretty': 728,\n",
       " 'good': 729,\n",
       " 'leadership': 730,\n",
       " 'talking': 731,\n",
       " 'about': 732,\n",
       " 'trade': 733,\n",
       " 'facilitation': 734,\n",
       " 'basically': 735,\n",
       " 'standards': 736,\n",
       " 'consistent': 737,\n",
       " 'harmonious': 738,\n",
       " 'across': 739,\n",
       " 'comprises': 740,\n",
       " 'private': 741,\n",
       " 'sector': 742,\n",
       " 'each': 743,\n",
       " '21': 744,\n",
       " 'economies': 745,\n",
       " 'meets': 746,\n",
       " 'times': 747,\n",
       " 'made': 748,\n",
       " 'permanent': 749,\n",
       " 'body': 750,\n",
       " '1995': 751,\n",
       " 'perspective': 752,\n",
       " 'within': 753,\n",
       " 'Members': 754,\n",
       " 'represent': 755,\n",
       " 'range': 756,\n",
       " 'sectors': 757,\n",
       " 'medium': 758,\n",
       " 'businesses': 759,\n",
       " 'need': 760,\n",
       " 'energy': 761,\n",
       " 'efficiency': 762,\n",
       " 'encourage': 763,\n",
       " 'conservation': 764,\n",
       " 'practices': 765,\n",
       " 'discuss': 766,\n",
       " 'ways': 767,\n",
       " 'enhance': 768,\n",
       " 'regional': 769,\n",
       " 'cooperation': 770,\n",
       " 'reckon': 771,\n",
       " \"'ll\": 772,\n",
       " 'talk': 773,\n",
       " 'little': 774,\n",
       " 'bit': 775,\n",
       " 'customs': 776,\n",
       " 'quarantine': 777,\n",
       " 'having': 778,\n",
       " 'arrangements': 779,\n",
       " 'around': 780,\n",
       " 'And': 781,\n",
       " 'want': 782,\n",
       " 'one-stop': 783,\n",
       " 'shop': 784,\n",
       " 'terms': 785,\n",
       " 'combining': 786,\n",
       " 'immigration': 787,\n",
       " 'together': 788,\n",
       " '\\x85': 789,\n",
       " 'just': 790,\n",
       " 'streamlined': 791,\n",
       " 'provides': 792,\n",
       " 'certainty': 793,\n",
       " 'non-governmental': 794,\n",
       " 'formal': 795,\n",
       " 'dialogue': 796,\n",
       " 'present': 797,\n",
       " 'meeting': 798,\n",
       " 'Sudan': 799,\n",
       " 'order': 800,\n",
       " 'Darfur': 801,\n",
       " 'asking': 802,\n",
       " 'same': 803,\n",
       " 'Foreign': 804,\n",
       " 'Minister': 805,\n",
       " 'Mustafa': 806,\n",
       " 'Osman': 807,\n",
       " 'Ismail': 808,\n",
       " 'Sudanese': 809,\n",
       " 'withdraw': 810,\n",
       " 'positions': 811,\n",
       " 'held': 812,\n",
       " 'April': 813,\n",
       " 'cease-fire': 814,\n",
       " 'western': 815,\n",
       " 'agree': 816,\n",
       " 'stop': 817,\n",
       " 'Mr.': 818,\n",
       " 'announced': 819,\n",
       " 'decision': 820,\n",
       " 'Nations': 821,\n",
       " 'African': 822,\n",
       " 'Khartoum': 823,\n",
       " 'weeks': 824,\n",
       " 'AU': 825,\n",
       " 'repeatedly': 826,\n",
       " 'truce': 827,\n",
       " 'head': 828,\n",
       " 'accused': 829,\n",
       " 'helicopters': 830,\n",
       " 'bombing': 831,\n",
       " 'rebel': 832,\n",
       " 'sites': 833,\n",
       " 'village': 834,\n",
       " 'Labado': 835,\n",
       " 'defending': 836,\n",
       " 'Aid': 837,\n",
       " 'relief': 838,\n",
       " 'efforts': 839,\n",
       " 'suspended': 840,\n",
       " 'due': 841,\n",
       " 'Indonesian': 842,\n",
       " 'men': 843,\n",
       " 'connection': 844,\n",
       " 'October': 845,\n",
       " '1': 846,\n",
       " 'Bali': 847,\n",
       " 'left': 848,\n",
       " '23': 849,\n",
       " 'dead': 850,\n",
       " 'flown': 851,\n",
       " 'Java': 852,\n",
       " 'island': 853,\n",
       " 'headquarters': 854,\n",
       " 'French': 855,\n",
       " 'agencies': 856,\n",
       " '(': 857,\n",
       " 'Cholily': 858,\n",
       " ')': 859,\n",
       " 'captured': 860,\n",
       " 'series': 861,\n",
       " 'counter-terrorism': 862,\n",
       " 'raids': 863,\n",
       " 'Indonesia': 864,\n",
       " 'ended': 865,\n",
       " 'death': 866,\n",
       " 'alleged': 867,\n",
       " 'extremist': 868,\n",
       " 'bombmaker': 869,\n",
       " 'Azahari': 870,\n",
       " 'bin': 871,\n",
       " 'Husin': 872,\n",
       " 'authorities': 873,\n",
       " 'blame': 874,\n",
       " 'orchestrating': 875,\n",
       " 'month': 876,\n",
       " 'well': 877,\n",
       " '2002': 878,\n",
       " 'Gunmen': 879,\n",
       " 'shot': 880,\n",
       " 'Roman': 881,\n",
       " 'Catholic': 882,\n",
       " 'nun': 883,\n",
       " 'her': 884,\n",
       " 'bodyguard': 885,\n",
       " 'hospital': 886,\n",
       " 'she': 887,\n",
       " 'worked': 888,\n",
       " 'Islamist-controlled': 889,\n",
       " 'Some': 890,\n",
       " 'witnesses': 891,\n",
       " 'shooting': 892,\n",
       " 'feared': 893,\n",
       " 'linked': 894,\n",
       " 'anger': 895,\n",
       " 'toward': 896,\n",
       " 'Pope': 897,\n",
       " 'Benedict': 898,\n",
       " 'pistols': 899,\n",
       " 'attacked': 900,\n",
       " 'Sister': 901,\n",
       " 'Leonella': 902,\n",
       " 'Sgorbati': 903,\n",
       " 'finished': 904,\n",
       " 'teaching': 905,\n",
       " 'medical': 906,\n",
       " 'school': 907,\n",
       " 'class': 908,\n",
       " 'suspect': 909,\n",
       " 'Vatican': 910,\n",
       " 'deplored': 911,\n",
       " 'hoped': 912,\n",
       " 'isolated': 913,\n",
       " 'event': 914,\n",
       " 'irrationality': 915,\n",
       " 'arising': 916,\n",
       " 'comments': 917,\n",
       " 'angered': 918,\n",
       " 'Muslims': 919,\n",
       " 'Authorities': 920,\n",
       " 'determined': 921,\n",
       " 'motive': 922,\n",
       " 'pope': 923,\n",
       " 'meant': 924,\n",
       " 'offense': 925,\n",
       " 'quoted': 926,\n",
       " '14': 927,\n",
       " 'century': 928,\n",
       " 'Byzantine': 929,\n",
       " 'emperor': 930,\n",
       " 'saying': 931,\n",
       " 'teachings': 932,\n",
       " 'Muhammed': 933,\n",
       " 'brought': 934,\n",
       " 'evil': 935,\n",
       " 'world': 936,\n",
       " 'targeted': 937,\n",
       " 'northwest': 938,\n",
       " 'third': 939,\n",
       " 'launching': 940,\n",
       " 'airstrikes': 941,\n",
       " 'suspected': 942,\n",
       " 'insurgents': 943,\n",
       " 'Helicopter': 944,\n",
       " 'gunships': 945,\n",
       " 'pounded': 946,\n",
       " 'hideouts': 947,\n",
       " 'Orakzai': 948,\n",
       " 'Taliban': 949,\n",
       " 'believed': 950,\n",
       " 'avoid': 951,\n",
       " 'nearby': 952,\n",
       " 'launched': 953,\n",
       " 'hunt': 954,\n",
       " 'So': 955,\n",
       " 'far': 956,\n",
       " 'nearly': 957,\n",
       " '100': 958,\n",
       " 'reported': 959,\n",
       " 'On': 960,\n",
       " 'dozens': 961,\n",
       " 'stormed': 962,\n",
       " 'checkpoint': 963,\n",
       " 'At': 964,\n",
       " '32': 965,\n",
       " 'counter-attack': 966,\n",
       " 'Elsewhere': 967,\n",
       " 'found': 968,\n",
       " 'bodies': 969,\n",
       " 'had': 970,\n",
       " 'Kurram': 971,\n",
       " 'along': 972,\n",
       " 'Afghan': 973,\n",
       " 'border': 974,\n",
       " 'few': 975,\n",
       " 'days': 976,\n",
       " 'ago': 977,\n",
       " 'separate': 978,\n",
       " 'clashes': 979,\n",
       " '13': 980,\n",
       " 'guerrillas': 981,\n",
       " 'two': 982,\n",
       " 'encounters': 983,\n",
       " 'central': 984,\n",
       " 'Uruzgan': 985,\n",
       " 'others': 986,\n",
       " 'injured': 987,\n",
       " 'fighting': 988,\n",
       " 'Another': 989,\n",
       " 'eastern': 990,\n",
       " 'Paktika': 991,\n",
       " 'Separately': 992,\n",
       " 'NATO-led': 993,\n",
       " 'peacekeeping': 994,\n",
       " 'mission': 995,\n",
       " 'early': 996,\n",
       " 'Mazar-e-Sharif': 997,\n",
       " 'motivated': 998,\n",
       " 'spared': 999,\n",
       " 'bloodshed': 1000,\n",
       " 'plagued': 1001,\n",
       " ...}"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "WpUQ-cuUhzgK",
    "outputId": "a93b5c20-4d0d-4c98-9940-ff9b102bfd76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word India is identified by the index: 2570\n",
      "The label B-org for the organization is identified by the index: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"The word India is identified by the index: {}\".format(word_to_index[\"India\"]))\n",
    "print(\"The label B-org for the organization is identified by the index: {}\".format(tag_to_index[\"B-org\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dnjrEHXVgki9"
   },
   "source": [
    "Defining parameters for LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "c0YiT3NcgoP4"
   },
   "outputs": [],
   "source": [
    "# Number of data points passed in each iteration\n",
    "batch_size = 64 \n",
    "# Passes through entire dataset\n",
    "epochs = 8\n",
    "# Maximum length of review\n",
    "max_len = 75 \n",
    "# Dimension of embedding vector\n",
    "embedding = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jFzV0CmzlpiX"
   },
   "source": [
    "Now we map the sentences to a sequence of numbers and then pad the sequence. Note that we increased the index of the words by one to use zero as a padding value. This is done because we want to use the mask_zero parameter of the embedding layer to ignore inputs with value zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vuRtqF4JjdYm",
    "outputId": "2ab3d97e-9de1-447c-b280-37fa34bfafde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T', 'h', 'o', 'u', 's', 'a', 'n', 'd', 's', ' ', 'o', 'f']"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting each sentence into list of indices from list of tokens\n",
    "# X = [[word_to_index[w[0]] for w in s] for s in sentences]\n",
    "\n",
    "# This line was obtained from source file:\n",
    "# https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb\n",
    "# It giving an error because it was splitting the sentence into characters and not into words. EG:\n",
    "[[w for w in s] for s in sentences][0][0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8lG20weD5i5V",
    "outputId": "f18f128a-9602-4a56-98dc-b879af2dfa70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thousands', 'NNS', 'O']"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Possible solution 1\n",
    "[[w for w in s] for s in sent][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ZUYtk1DX56WB",
    "outputId": "79124afc-2e29-4b4e-d82a-f645a9694a7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T', 'N', 'O']"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem with possible solution 1\n",
    "[[w[0] for w in s] for s in sent][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "qigtdw7i5MeL",
    "outputId": "22b0b231-2b68-4ef1-ea88-01ae3f0a756a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thousands', 'NNS', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('demonstrators', 'NNS', 'O'),\n",
       " ('have', 'VBP', 'O'),\n",
       " ('marched', 'VBN', 'O'),\n",
       " ('through', 'IN', 'O'),\n",
       " ('London', 'NNP', 'B-geo'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('protest', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('war', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('Iraq', 'NNP', 'B-geo'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('demand', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('withdrawal', 'NN', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('British', 'JJ', 'B-gpe'),\n",
       " ('troops', 'NNS', 'O'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('that', 'DT', 'O'),\n",
       " ('country', 'NN', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing possible solution 2\n",
    "[[s for s in sent] for sent in getter.sentences][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "7gCK_nYJ6qoG",
    "outputId": "2c8239fd-a7ee-4edd-dac2-c99ff5d0761e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thousands',\n",
       " 'of',\n",
       " 'demonstrators',\n",
       " 'have',\n",
       " 'marched',\n",
       " 'through',\n",
       " 'London',\n",
       " 'to',\n",
       " 'protest',\n",
       " 'the',\n",
       " 'war',\n",
       " 'in',\n",
       " 'Iraq',\n",
       " 'and',\n",
       " 'demand',\n",
       " 'the',\n",
       " 'withdrawal',\n",
       " 'of',\n",
       " 'British',\n",
       " 'troops',\n",
       " 'from',\n",
       " 'that',\n",
       " 'country',\n",
       " '.']"
      ]
     },
     "execution_count": 110,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can word be fetched from possible solution 2?\n",
    "[[s[0] for s in sent] for sent in getter.sentences][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fJ34LUjQs9-i"
   },
   "outputs": [],
   "source": [
    "# To correct above error, editing code to following:\n",
    "X = [[word_to_index[s[0]] for s in sent] for sent in getter.sentences]\n",
    "\n",
    "# Padding each sequence to have same length  of each word\n",
    "# keras method \n",
    "X = pad_sequences(maxlen = max_len, sequences = X, padding = \"post\", value = word_to_index[\"PAD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "uoEa0tKN2Dzl",
    "outputId": "5d7408dc-7268-41c2-dfc0-2e1d12580af5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2,    3,    4, ...,    0,    0,    0],\n",
       "       [ 126,  127,  128, ...,    0,    0,    0],\n",
       "       [ 944,  945,  365, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [3185,  112,   70, ...,    0,    0,    0],\n",
       "       [6504, 3208,   95, ...,    0,    0,    0],\n",
       "       [  63,  582,  821, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "apyr9bI6mE8t"
   },
   "outputs": [],
   "source": [
    "# Convert label to index\n",
    "y = [[tag_to_index[s[2]] for s in sent] for sent in getter.sentences]\n",
    "\n",
    "# padding\n",
    "y = pad_sequences(maxlen = max_len, sequences = y, padding = \"post\", value = tag_to_index[\"PAD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "wbsZl3pi2PoP",
    "outputId": "e69a7ee5-5e7b-4481-8257-776b422a64fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [3, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 8, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 2, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 6, 7, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qhC1JgIy2Xqy"
   },
   "outputs": [],
   "source": [
    "num_tag = df['Tag'].nunique()\n",
    "# One hot encoded labels\n",
    "y = [to_categorical(i, num_classes = num_tag + 1) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "colab_type": "code",
    "id": "oOtzqxCe3Cd_",
    "outputId": "2d7b2e5a-3ed9-4a4c-aa0d-d874135d7af8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 96,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "X3fsty5j3fxP"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "yekDeAfn3i1s",
    "outputId": "a9139c92-2fb2-423d-d130-69f61e16bfd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training input data :  (40765, 75)\n",
      "Size of training output data :  (40765, 75, 18)\n",
      "Size of testing input data :  (7194, 75)\n",
      "Size of testing output data :  (7194, 75, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of training input data : \", X_train.shape)\n",
    "print(\"Size of training output data : \", np.array(y_train).shape)\n",
    "print(\"Size of testing input data : \", X_test.shape)\n",
    "print(\"Size of testing output data : \", np.array(y_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "colab_type": "code",
    "id": "BsvjHDA88KSC",
    "outputId": "c643fc15-2a81-4555-8fd7-0e3177dc5ab9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Before Processing first sentence : *****\n",
      " Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
      "*****After Processing first sentence : *****\n",
      "  [ 2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 11 17  3 18 19 20 21 22 23\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "# Let's check the first sentence before and after processing.\n",
    "print('*****Before Processing first sentence : *****\\n', ' '.join([w[0] for w in getter.sentences[0]]))\n",
    "print('*****After Processing first sentence : *****\\n ', X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "CuK_vgNd8TEr",
    "outputId": "2a3ca952-d34e-4eea-a5b6-1f11988b38f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Before Processing first sentence : *****\n",
      " O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O\n",
      "*****After Processing first sentence : *****\n",
      "  [[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# First label before and after processing.\n",
    "print('*****Before Processing first sentence : *****\\n', ' '.join([w[2] for w in getter.sentences[0]]))\n",
    "print('*****After Processing first sentence : *****\\n ', y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aOcfRqra8_UJ"
   },
   "source": [
    "### Bidirectional LSTM-CRF Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "colab_type": "code",
    "id": "p9tdgEBi88FO",
    "outputId": "a4bfac05-7adf-4188-f09e-3165d8d139a3"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-11341c375c5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCRF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_tags\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# CRF layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:292 call  *\n        test_output = self.viterbi_decoding(X, mask)\n    /usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:564 viterbi_decoding  *\n        argmin_tables = self.recursion(input_energy, mask, return_logZ=False)\n    /usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:521 _step  *\n        return self.step(input_energy_i, states, return_logZ)\n    /usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:463 step  *\n        m = K.slice(states[3], [0, t], [-1, 2])\n\n    AttributeError: module 'keras.backend' has no attribute 'slice'\n"
     ]
    }
   ],
   "source": [
    "num_tags = df['Tag'].nunique()\n",
    "\n",
    "# Model architecture\n",
    "\n",
    "# Instantiate a Keras tensor\n",
    "input = Input(shape = (max_len,))\n",
    "\n",
    "#turn positive integers (indexes) into dense vectors of fixed size\n",
    "model = Embedding(input_dim = len(words) + 2, output_dim = embedding, input_length = max_len, mask_zero = True)(input)\n",
    "\n",
    "# Bidirectional wrapper for RNNs\n",
    "model = Bidirectional(LSTM(units = 50, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)\n",
    "crf = CRF(num_tags+1)  # CRF layer\n",
    "out = crf(model)  # output\n",
    "\n",
    "model = Model(input, out)\n",
    "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath = 'model.h5',\n",
    "                       verbose = 0,\n",
    "                       mode = 'auto',\n",
    "                       save_best_only = True,\n",
    "                       monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, np.array(y_train), batch_size=batch_size, epochs=epochs,\n",
    "                    validation_split=0.1, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = history.history['crf_viterbi_accuracy']\n",
    "val_acc = history.history['val_crf_viterbi_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.figure(figsize = (8, 8))\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 8))\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "y_test_true = np.argmax(y_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the index to tag\n",
    "y_pred = [[idx2tag[i] for i in row] for row in y_pred]\n",
    "y_test_true = [[idx2tag[i] for i in row] for row in y_test_true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"F1-score is : {:.1%}\".format(f1_score(y_test_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report = flat_classification_report(y_pred=y_pred, y_true=y_test_true)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# At every execution model picks some random test sample from test set.\n",
    "i = np.random.randint(0,X_test.shape[0]) # choose a random number between 0 and len(X_te)b\n",
    "p = model.predict(np.array([X_test[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "true = np.argmax(y_test[i], -1)\n",
    "\n",
    "print(\"Sample number {} of {} (Test Set)\".format(i, X_test.shape[0]))\n",
    "# Visualization\n",
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")\n",
    "for w, t, pred in zip(X_test[i], true, p[0]):\n",
    "    if w != 0:\n",
    "        print(\"{:15}: {:5} {}\".format(words[w-2], idx2tag[t], idx2tag[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('word_to_index.pickle', 'wb') as f:\n",
    "    pickle.dump(word_to_index, f)\n",
    "\n",
    "with open('tag_to_index.pickle', 'wb') as f:\n",
    "    pickle.dump(tag_to_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Welcome To Colaboratory",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
